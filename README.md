# BiasLens
This tool helps users identify and reflect on gender-coded language in job descriptions or text. It highlights masculine or feminine-coded words and suggests more inclusive alternatives. The goal is to raise awareness about subtle linguistic biases and encourage more equitable communication.

## Step 1: AI Core: Bias Detection + Neutral Word Suggestions

Example: Input "Gotta be assertive and confident bros." -> male bias detected -> 
neutral word suggestions: "assertive":["confident","clear-communicating"],"bros":["people","humans","employees"],"confident":["capable","self-assured"]
<img width="1864" height="174" alt="image" src="https://github.com/user-attachments/assets/cda97ef8-235b-4abd-aa84-98a052d3112a" />

## Step 2: Backend + Frontend 
<img width="3452" height="1798" alt="image" src="https://github.com/user-attachments/assets/e3e82f09-f34f-4097-a62e-e1477b84c031" />
