## BiasLens
This tool helps users identify and reflect on gender-coded language in job descriptions or text. It highlights masculine or feminine-coded words and suggests more inclusive alternatives. The goal is to raise awareness about subtle linguistic biases and encourage more equitable communication.

# Step 1
AI Core: Bias Detection + Neutral Word Suggestions

Example: Input "Gotta be assertive and confident bros." -> male bias detected -> 
neutral word suggestions: "assertive":["confident","clear-communicating"],"bros":["people","humans","employees"],"confident":["capable","self-assured"]
<img width="1864" height="174" alt="image" src="https://github.com/user-attachments/assets/cda97ef8-235b-4abd-aa84-98a052d3112a" />
